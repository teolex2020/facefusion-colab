{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRirbUx4CObO"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaqO7feu9sAw",
        "outputId": "e24d5360-1a53-4605-b389-4d2867a30f26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Installed!\n"
          ]
        }
      ],
      "source": [
        "from IPython.display import clear_output\n",
        "import codecs\n",
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device=\"cuda\"\n",
        "  !apt-get install nvidia-cuda-toolkit\n",
        "  print(\"Using GPU\")\n",
        "else:\n",
        "  device=\"cpu\"\n",
        "  print(\"Using CPU\")\n",
        "\n",
        "giturl = codecs.decode('uggcf://tvguho.pbz/Mnpulfnhef/snprshfvba.tvg','rot_13')\n",
        "gitdir = codecs.decode('snprshfvba','rot_13')\n",
        "!git clone {giturl}\n",
        "%cd /content/{gitdir}\n",
        "!python install.py --onnxruntime cuda-11.8 --skip-conda\n",
        "\n",
        "clear_output()\n",
        "print(\"Installed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4G9Q3opCNeg"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uw9meeAfCVsM"
      },
      "source": [
        "# Run with local gradio if it work"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uuDaRgITCHBk"
      },
      "outputs": [],
      "source": [
        "import codecs\n",
        "gitdir = codecs.decode('snprshfvba','rot_13')\n",
        "%cd /content/{gitdir}\n",
        "\n",
        "if device==\"cuda\":\n",
        "  !python run.py --execution-providers cpu cuda\n",
        "else:\n",
        "  !python run.py --execution-providers cpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FHQTs-RCb2N"
      },
      "source": [
        "# Run with local tunnal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2JW6sWUcB_xl"
      },
      "outputs": [],
      "source": [
        "!npm install -g localtunnel\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "import socket\n",
        "import urllib.request\n",
        "def iframe_thread(port):\n",
        "    while True:\n",
        "        time.sleep(0.5)\n",
        "        sock= socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "        result = sock.connect_ex(('127.0.0.1', port))\n",
        "        if result == 0:\n",
        "            break\n",
        "        sock.close()\n",
        "\n",
        "        from colorama import Fore, Style\n",
        "    print (Fore.GREEN + \"\\nIP: \", Fore. RED, urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\"), \"\\n\", Style. RESET_ALL)\n",
        "    p = subprocess.Popen([\"lt\", \"--port\", \"{}\".format(port)], stdout=subprocess.PIPE)\n",
        "    for line in p.stdout:\n",
        "        print(line.decode(), end='')\n",
        "threading.Thread (target=iframe_thread, daemon=True, args=(7860,)).start()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "!python run.py"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
